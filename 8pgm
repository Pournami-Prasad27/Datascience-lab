from sklearn.datasets import  load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
iris=load_iris()
x=iris.data
y=iris.target
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)
c_knn=KNeighborsClassifier(n_neighbors=3)
c_knn.fit(x_train,y_train)
y_pred=c_knn.predict(x_test)
print("accuracy",metrics.accuracy_score(y_test,y_pred))
sample=[[2,2,2,2]]
pred=c_knn.predict(sample)
pred_v=[iris.target_names[i] for i in pred]
print(pred_v)




naive
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
X,y=load_iris(return_X_y=True)
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=0)
gnb=GaussianNB()
y_pred=gnb.fit(X_train,y_train).predict(X_test)
print(y_pred)
x_new=[[5,5,4,4]]
y_new=gnb.fit(X_train,y_train).predict(x_new)
print("predicted output for [[5,5,4,4]]:",y_new)
print("Naive bayes score:",gnb.score(X_test,y_test))


linear
import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets,linear_model
from sklearn.metrics import mean_squared_error,r2_score
df =datasets.load_diabetes()
df['feature_names']
diabetes_X,diabetes_y=datasets.load_diabetes(return_X_y=True)
diabetes_X.shape
diabetes_y.shape
diabetes_X=diabetes_X[:,np.newaxis,2]
diabetes_X.shape
diabetes_X_train=diabetes_X[:-20]
diabetes_X_test=diabetes_X[-20:]
diabetes_y_train=diabetes_y[:-20]
diabetes_y_test=diabetes_y[-20:]
regr=linear_model.LinearRegression()
regr.fit(diabetes_X_train,diabetes_y_train)
diabetes_y_pred=regr.predict(diabetes_X_test)
print("coefficients :\n",regr.coef_)
print("meansquareerror:%2f"%mean_squared_error(diabetes_y_test,diabetes_y_pred))
print("coefficient of determination:%2f"%r2_score(diabetes_y_test,diabetes_y_pred))
plt.scatter(diabetes_X_test,diabetes_y_pred,color="blue",linewidth=3)
plt.ylabel("diabetes progression")
plt.xticks(())
plt.yticks(())
plt.show(())

DT
from sklearn.datasets import load_iris
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
import matplotlib.pyplot as plt

iris = load_iris()
x = iris.data
y = iris.target

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=1)

clf = DecisionTreeClassifier()
clf.fit(x_train, y_train)

y_pred = clf.predict(x_test)

print("Accuracy: ", metrics.accuracy_score(y_test, y_pred))

plt.figure(figsize=(15, 15))
plot_tree(clf, fontsize=10, filled=True, rounded=True, class_names=list(iris.target_names), feature_names=iris.feature_names)
plt.show()

MATPLOTLIB

import numpy as np
a=np.array([1,2,3])
print("one dimensional array a=",a)
b=np.array([[1,2,3],[4,5,6]])
print("two dimensional array b=",b)
print("size of the array:",a.shape)
print ("element at the indices 0,1,2:",a[0],a[1],a[2])
a[0]=5
print("array after changing:",a)
a=np.zeros((2,2))
print("all the elements are 0",a)
b=np.ones((1,2))
print("an array  of all ones:",b)
c=np.full(2,2)
print(" constant array:",c)
d=np.eye(2)
print("a 2*2 identity matrix:",d)
e=np.random.random((2,2))
print("an array with andom values:",e)
